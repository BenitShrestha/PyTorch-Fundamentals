{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "c794994f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting PyTorch Fundamentals\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting PyTorch Fundamentals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "721666e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "f124822f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619a0b0",
   "metadata": {},
   "source": [
    "**Introduction to Tensors**\n",
    "\n",
    "Creating Tensors\n",
    "\n",
    "PyTorch Tensors are created using *torch.tensor()*.\n",
    "\n",
    "Basic nomenclature: \n",
    "- scalar, vector - Lower Case\n",
    "- MATRIX, TENSOR - Upper Case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b75142",
   "metadata": {},
   "source": [
    "**Scalar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "2b9a3a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 852,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "id": "2a456b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 853,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functions\n",
    "'''Checks dimension of the tensor, scalar has no dimension'''\n",
    "scalar.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "4ecf8175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 854,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python integer\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5811704",
   "metadata": {},
   "source": [
    "**Vector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "id": "b47ed09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7, 8])"
      ]
     },
     "execution_count": 855,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7,7,8])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "id": "f6f3151e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim # 1D, 1 pair of closing square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "id": "71c8c18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape # 3 elements in vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a419f484",
   "metadata": {},
   "source": [
    "**MATRIX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "8d41c12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8, 10],\n",
       "        [ 9,  6,  5]])"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX = torch.tensor([\n",
    "    [7, 8, 10],\n",
    "    [9, 6, 5] # Can't do [9, 6, 5, 4], Dimension Mismatch\n",
    "])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "1e5302b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 859,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim # 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "5485bbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 860,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape # 2 rows, 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "3fec6714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7,  8, 10])"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0] # Accessing elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "998cf19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 862,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1][0] # Inner access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c876559",
   "metadata": {},
   "source": [
    "**TENSOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "a6540fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "94fa4821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 864,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "a623b946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape # 1 batch, 3 rows, 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "32a4182e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "fce3eda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "93af8e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "187d2f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0][1][2] # 3D for this reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "b06bf138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2, 3],\n",
       "          [2, 3, 4],\n",
       "          [4, 5, 6]],\n",
       "\n",
       "         [[1, 2, 4],\n",
       "          [3, 4, 7],\n",
       "          [5, 6, 9]]]])"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR2 = torch.tensor([[\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [2,3,4],\n",
    "        [4,5,6]\n",
    "    ],\n",
    "    [\n",
    "        [1,2,4],\n",
    "        [3,4,7],\n",
    "        [5,6,9]\n",
    "    ]\n",
    "]])\n",
    "TENSOR2 # Same no. of elements inside each square bracket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "3b84bf1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR2.ndim # 4 levels of square brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "92d6625c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 3])"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR2.shape \n",
    "# 1 main batch, 2 sub-batches each with 3 rows and 3 columns of elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "49418cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1, 2, 3],\n",
       "          [2, 3, 4],\n",
       "          [4, 5, 6]],\n",
       "\n",
       "         [[1, 2, 4],\n",
       "          [3, 4, 7],\n",
       "          [5, 6, 9]]]])"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aab67ca",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "\n",
    "**Why random tensors?**\n",
    "\n",
    "Random tensors are important because the way many NN learn it that they start with tensors full of random numbers and then adjust those random numbers to better represent the data. \n",
    "\n",
    "`Start with random variables -> Look at data -> Update random numbers -> Look at data -> Update random numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "264bab5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.8722, 0.9650, 0.7837, 0.8076],\n",
       "          [0.0608, 0.7226, 0.3354, 0.5350],\n",
       "          [0.7117, 0.7979, 0.2785, 0.8947]],\n",
       "\n",
       "         [[0.6694, 0.8950, 0.4479, 0.4788],\n",
       "          [0.3541, 0.0467, 0.7471, 0.7821],\n",
       "          [0.4296, 0.1128, 0.8413, 0.4978]]]])"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random tensor of size (3,4)\n",
    "random_tensor = torch.rand(1, 2, 3, 4)\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "c65261b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "656d5adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3, 4])"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.shape \n",
    "# Total number of elements: 1*2*3*4, so 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "84eb4fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([224, 224, 3]))"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a random tensor with similar shpae to an image tensor\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # Height, Width, Color Channel\n",
    "random_image_size_tensor.ndim, random_image_size_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "830ab56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, torch.Size([224, 224, 4]))"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_img_tensor2 = torch.rand(224,224,4) # Works the same without using size=()\n",
    "rand_img_tensor2.ndim, rand_img_tensor2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72de48a",
   "metadata": {},
   "source": [
    "**Random Tensors with 1s and 0s**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "be08f41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "54612fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size=(3,4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "47d1ac35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros*ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "33a79a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype # Datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "41e178c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' zeros*rand_img_tensor2 '"
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' zeros*rand_img_tensor2 ''' # Dimension Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574e0792",
   "metadata": {},
   "source": [
    "### Creating a range of tensors and tensors-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "f8e9cd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\AppData\\Local\\Temp\\ipykernel_27804\\2245269920.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  range_tensor = torch.range(2,6) # Depreciated, Goes from 2 to 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([2., 3., 4., 5., 6.]), tensor([5, 6, 7, 8]))"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using torch.range()\n",
    "range_tensor = torch.range(2,6) # Depreciated, Goes from 2 to 6\n",
    "range_tensor2 = torch.arange(5,9) # Goes from 5 to 8\n",
    "range_tensor, range_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "cbfd6f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor = torch.arange(start=1, end=11, step=1)\n",
    "new_tensor # Ends at (end - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "e59607b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2,  8, 14, 20, 26, 32, 38, 44, 50, 56, 62, 68, 74, 80])"
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor2 = torch.arange(start=2, end=81, step=6)\n",
    "new_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "56c048d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tensors like - Copying the shape\n",
    "new_tensor_zeros = torch.zeros_like(input=new_tensor)\n",
    "new_tensor_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "4de28f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor_ones = torch.ones_like(input=new_tensor)\n",
    "new_tensor_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8cecfe",
   "metadata": {},
   "source": [
    "### Dealing with tensor datatypes\n",
    "\n",
    "**Note**: Errors faced while running PyTorch and in Deep Learning\n",
    "\n",
    "1. Incorrect datatype\n",
    "2. Incorrect Shape\n",
    "3. Not on right device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "0a0a48f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.2000, 5.6000, 7.8000])"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Float 32 Tensor\n",
    "float_32_tensor = torch.tensor([3.2, 5.6, 7.8],\n",
    "                               dtype=None, # Datatype float16, float32, float64\n",
    "                               device='cpu', # CPU or GPU-Cuda?\n",
    "                               requires_grad=False) # To track gradients or not?\n",
    "float_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "e5dc613e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "9ef01d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1992, 5.6016, 7.8008], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 891,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype16_tensor = torch.tensor([3.2, 5.6, 7.8],\n",
    "                            dtype=torch.float16,\n",
    "                            device='cuda')\n",
    "dtype16_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "c6e1f1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float16"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype16_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "26c575ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'float_32_tensor*dtype_tensor'"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''float_32_tensor*dtype_tensor''' # Doesn't work since 1 tensor is in CPU another in GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "id": "207cff7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1992, 5.6016, 7.8008], dtype=torch.float16)"
      ]
     },
     "execution_count": 894,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_16_tensor = float_32_tensor.type(torch.float16)\n",
    "float_16_tensor # Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "id": "a6bf8769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.1992, 5.6016, 7.8008], device='cuda:0')"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype32_tensor = dtype16_tensor.type(torch.float32)\n",
    "dtype32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "id": "dc42ce73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.4404, 2.3008, 3.5547], dtype=torch.float16),\n",
       " tensor([4.0000, 5.8800, 6.9000]),\n",
       " tensor([7.3333, 8.2000, 9.9900], dtype=torch.float64))"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f16 = torch.tensor([1.44,2.3,3.555], dtype=torch.float16)\n",
    "f32 = torch.tensor([4,5.88,6.9], dtype=torch.float32)\n",
    "f64 = torch.tensor([7.3333,8.2,9.99], dtype=torch.float64)\n",
    "\n",
    "f16, f32, f64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "id": "325c93bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5.7617, 13.5286, 24.5273]), torch.float32)"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f16*f32, (f16*f32).dtype # Works!, changes to higher precision dtype i.e float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "id": "3e3a4273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([29.3332, 48.2160, 68.9310], dtype=torch.float64),\n",
       " tensor([10.5631, 18.8664, 35.5113], dtype=torch.float64))"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f32*f64, f16*f64 # Works!, changes to float64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94642251",
   "metadata": {},
   "source": [
    "# Getting Tensor Attributes\n",
    "## Information about Tensors\n",
    "\n",
    "- Shape: `tensor.shape`\n",
    "- Datatype: `tensor.dtype`\n",
    "- Device: `tensor.device`\n",
    "\n",
    "### Using Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "id": "b1a457ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3422, 0.6463, 0.0694, 0.4335],\n",
       "         [0.3440, 0.3562, 0.0282, 0.0583],\n",
       "         [0.8533, 0.9505, 0.5430, 0.8421]]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 899,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor, some_tensor.size() # Same as shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "id": "62d942b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datatype:  torch.float32\n",
      "Shape:  torch.Size([3, 4])\n",
      "Device:  cpu\n"
     ]
    }
   ],
   "source": [
    "print('Datatype: ', some_tensor.dtype)\n",
    "print('Shape: ', some_tensor.shape)\n",
    "print('Device: ', some_tensor.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47203334",
   "metadata": {},
   "source": [
    "### Manipulating Tensor Attributes\n",
    "#### Tensor Operations\n",
    "- Addition \n",
    "- Subtraction \n",
    "- Multiplication (Element-wise)\n",
    "- Division\n",
    "- Matrix Multiplication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "id": "26cca0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atensor = torch.tensor([1,2,3])\n",
    "atensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "id": "cc3d823f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 13])"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atensor + 10 # Adds 10 to all elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "id": "63fb936f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4, -3, -2])"
      ]
     },
     "execution_count": 903,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atensor - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "id": "cdf0741e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8, 16, 24])"
      ]
     },
     "execution_count": 904,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atensor * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "id": "8ceb3ec9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3333, 0.6667, 1.0000])"
      ]
     },
     "execution_count": 905,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atensor / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "34b46838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1])"
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atensor // 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "id": "c4c6de0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 12, 18])"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PyTorch Inbuilt Functions\n",
    "torch.mul(atensor, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "7a0eb754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 7, 8])"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(atensor, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed665c57",
   "metadata": {},
   "source": [
    "### Matrix Multiplication\n",
    "\n",
    "Two main ways of performing multiplication in NN and Deep Learning:\n",
    "\n",
    "1. Element wise multiplication \n",
    "2. Matrix Multiplication / Dot Product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "id": "205ef094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
      "= tensor([1, 4, 9])\n"
     ]
    }
   ],
   "source": [
    "# Element wise Multiplication\n",
    "print(atensor, '*', atensor)\n",
    "print('=', (atensor*atensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "id": "07146d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix Multiplication\n",
    "torch.matmul(atensor, atensor) \n",
    "# 1*1+2*2+3*3 = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "id": "92608f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 998 Âµs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "value = 0\n",
    "for i in range(len(atensor)):\n",
    "    value += atensor[i] * atensor[i]\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "id": "d995bfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(14)"
      ]
     },
     "execution_count": 912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(atensor, atensor) # Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4aee5",
   "metadata": {},
   "source": [
    "### Two main rules for performing matrix multiplication\n",
    "1. The **inner dimensions** must match:\n",
    "* `(3 ,2) @ (3, 2)` won't work\n",
    "* `(3, 2) @ (2, 3)` works\n",
    "2. The resulting matrix has the shape of the **outer dimensions**.\n",
    "* `(3, 2) @ (2 ,3) -> (3, 3)`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "id": "1ee2303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = torch.rand(3,2)\n",
    "tensor_2 = torch.rand(3,2)\n",
    "tensor_3 = torch.rand(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "id": "af80a0cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.matmul(tensor_1, tensor_2)'"
      ]
     },
     "execution_count": 914,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''torch.matmul(tensor_1, tensor_2)''' # Shape error, both (3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "id": "18a311f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3568, 0.9743, 0.6070, 0.5910],\n",
       "        [0.1139, 0.2835, 0.1585, 0.1885],\n",
       "        [0.2268, 0.7316, 0.5297, 0.3765]])"
      ]
     },
     "execution_count": 915,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor_1, tensor_3) # New matrix is (3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e62dacd",
   "metadata": {},
   "source": [
    "### Shape Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "id": "5a3d697a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.matmul(tensor_A, tensor_B)'"
      ]
     },
     "execution_count": 916,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A = torch.tensor([\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "    [5,6]\n",
    "])\n",
    "\n",
    "tensor_B = torch.tensor([\n",
    "    [2,3],\n",
    "    [5,6],\n",
    "    [7,8]\n",
    "])\n",
    "\n",
    "'''torch.matmul(tensor_A, tensor_B)''' # 3 by 2 and 3 by 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "5a53ec67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2, 5, 7],\n",
       "         [3, 6, 8]]),\n",
       " tensor([[2, 3],\n",
       "         [5, 6],\n",
       "         [7, 8]]))"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Matrix Transpose: Switches axes or dimensions of a matrix\n",
    "tensor_B.T, tensor_B # From 3,2 to 2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "id": "d26cbc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.shape, tensor_B.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "id": "747aa3e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8, 17, 23],\n",
       "        [18, 39, 53],\n",
       "        [28, 61, 83]])"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T) # Works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "id": "072d59fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 920,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(tensor_A, tensor_B.T).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb452b1",
   "metadata": {},
   "source": [
    "### Tensor Aggregation - Max, Min, Mean, Sum \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "453585aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtens = torch.arange(start=0, end=100, step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "id": "e67d5c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 20, 40, 60, 80])"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "id": "af193416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(0))"
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(xtens), xtens.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "862ce56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(80), tensor(80))"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(xtens), xtens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "id": "151e4a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtens.dtype # Mean function can't work with int64 or Long int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "id": "fffab469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40., dtype=torch.float16)"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtens = xtens.type(torch.float16)\n",
    "xtens.mean() # Doesn't work with int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "id": "4d7a0e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(40., dtype=torch.float64)"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(xtens.type(torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "1dcae0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(200., dtype=torch.float16), tensor(200., dtype=torch.float16))"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(xtens), xtens.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6c71ae",
   "metadata": {},
   "source": [
    "### Finding positional min and max\n",
    "Index of minimum and maximum\n",
    "\n",
    "- `tensor.argmin()` -> Returns index position of target tensor where minimum value occurs\n",
    "- `tensor.argmax()` -> Returns index position of target tensor where maximum value occurs, needed later on for Softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "f3ef4138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0), tensor(4))"
      ]
     },
     "execution_count": 929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtens.argmin(), xtens.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "id": "64004b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytens = torch.rand(1,2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "id": "eb3bdb09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0168, 0.8506, 0.5325, 0.4284],\n",
       "          [0.0743, 0.0911, 0.6694, 0.1401],\n",
       "          [0.4400, 0.7214, 0.8828, 0.2290]],\n",
       "\n",
       "         [[0.3566, 0.6354, 0.6072, 0.8164],\n",
       "          [0.9520, 0.7464, 0.9612, 0.5058],\n",
       "          [0.2447, 0.3062, 0.5583, 0.9522]]]])"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "93638eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5299)"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytens.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "id": "860644e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9612)"
      ]
     },
     "execution_count": 933,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytens.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "404317a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9612)"
      ]
     },
     "execution_count": 934,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytens[0][1].max() # Index wise aggregation too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "id": "51072919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.5058), tensor(0.7913))"
      ]
     },
     "execution_count": 935,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytens[0][1][1].min(), ytens[0][1][1].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de564c18",
   "metadata": {},
   "source": [
    "## Reshaping, Stacking, Squeezing and Unsqueezing Tensors\n",
    "- **Reshaping** - Reshapes an input tensor to a defined tensor\n",
    "- **View** - Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "- **Stacking** - Combine multiple tensors on top of each each (vstack) or side by side (hstack)\n",
    "- **Squeeze** - Removes all `1` dimensions from a tensor\n",
    "- **Unsqueeze** - Add a `1` dimension to a target tensor\n",
    "- **Permute** - Return a view of the input with dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "id": "98ad3c26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,\n",
       "         90, 95]),\n",
       " torch.Size([20]))"
      ]
     },
     "execution_count": 936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztens = torch.arange(0, 100, 5)\n",
    "ztens, ztens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "id": "a24506b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,\n",
       "          90, 95]]),\n",
       " torch.Size([1, 20]))"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension - 1 more square bracket\n",
    "ztens_reshaped = ztens.reshape(1, 20) # 1 row, 20 cols\n",
    "ztens_reshaped, ztens_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "id": "2d6286e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0],\n",
       "         [ 5],\n",
       "         [10],\n",
       "         [15],\n",
       "         [20],\n",
       "         [25],\n",
       "         [30],\n",
       "         [35],\n",
       "         [40],\n",
       "         [45],\n",
       "         [50],\n",
       "         [55],\n",
       "         [60],\n",
       "         [65],\n",
       "         [70],\n",
       "         [75],\n",
       "         [80],\n",
       "         [85],\n",
       "         [90],\n",
       "         [95]]),\n",
       " torch.Size([20, 1]))"
      ]
     },
     "execution_count": 938,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ztens_reshaped_2 = ztens.reshape(20, 1) # 20 rows, 1 col\n",
    "ztens_reshaped_2, ztens_reshaped_2.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "id": "bee97ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  5],\n",
       "          [10, 15],\n",
       "          [20, 25],\n",
       "          [30, 35],\n",
       "          [40, 45]],\n",
       " \n",
       "         [[50, 55],\n",
       "          [60, 65],\n",
       "          [70, 75],\n",
       "          [80, 85],\n",
       "          [90, 95]]]),\n",
       " torch.Size([2, 5, 2]))"
      ]
     },
     "execution_count": 939,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original shape is 20 so can be reshaped into combinations that yield 20 when multiplied\n",
    "ztens_reshap_3 = ztens.reshape(2, 5, 2) # (2, 10), (4, 5)\n",
    "ztens_reshap_3, ztens_reshap_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "id": "aeff03ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0,  5],\n",
       "          [10, 15],\n",
       "          [20, 25],\n",
       "          [30, 35],\n",
       "          [40, 45]],\n",
       " \n",
       "         [[50, 55],\n",
       "          [60, 65],\n",
       "          [70, 75],\n",
       "          [80, 85],\n",
       "          [90, 95]]]),\n",
       " torch.Size([2, 5, 2]))"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the view\n",
    "z = ztens.view(2,5,2)\n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b37b193",
   "metadata": {},
   "source": [
    "### Changing `z` change `ztens` because a view of a tensor shares the same memory as the original input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "id": "7ad39209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[66,  5],\n",
       "          [10, 15],\n",
       "          [20, 25],\n",
       "          [30, 35],\n",
       "          [40, 45]],\n",
       " \n",
       "         [[50, 55],\n",
       "          [60, 65],\n",
       "          [70, 75],\n",
       "          [80, 85],\n",
       "          [90, 95]]]),\n",
       " tensor([66,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,\n",
       "         90, 95]))"
      ]
     },
     "execution_count": 941,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[0][0][0] = 66\n",
    "z, ztens # First element of both tensors changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "id": "8b6d6758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[33, 33],\n",
       "          [10, 15],\n",
       "          [20, 25],\n",
       "          [30, 35],\n",
       "          [40, 45]],\n",
       " \n",
       "         [[33, 33],\n",
       "          [60, 65],\n",
       "          [70, 75],\n",
       "          [80, 85],\n",
       "          [90, 95]]]),\n",
       " tensor([33, 33, 10, 15, 20, 25, 30, 35, 40, 45, 33, 33, 60, 65, 70, 75, 80, 85,\n",
       "         90, 95]))"
      ]
     },
     "execution_count": 942,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 0] = 33 # Changes all elements at 0th index of all batches to 33\n",
    "z, ztens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "id": "7e3e6923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65]),\n",
       " tensor([[ 5],\n",
       "         [10],\n",
       "         [15],\n",
       "         [20],\n",
       "         [25],\n",
       "         [30],\n",
       "         [35],\n",
       "         [40],\n",
       "         [45],\n",
       "         [50],\n",
       "         [55],\n",
       "         [60],\n",
       "         [65]]))"
      ]
     },
     "execution_count": 943,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "btens = torch.arange(5, 70, 5)\n",
    "btens.shape\n",
    "btens, btens.reshape(13, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "id": "183aacdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65],\n",
       "        [ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65],\n",
       "        [ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65]])"
      ]
     },
     "execution_count": 944,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_stacked0 = torch.stack([btens, btens, btens], dim=0) # Row Stacking\n",
    "b_stacked0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "id": "09106e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  5,  5],\n",
       "        [10, 10, 10],\n",
       "        [15, 15, 15],\n",
       "        [20, 20, 20],\n",
       "        [25, 25, 25],\n",
       "        [30, 30, 30],\n",
       "        [35, 35, 35],\n",
       "        [40, 40, 40],\n",
       "        [45, 45, 45],\n",
       "        [50, 50, 50],\n",
       "        [55, 55, 55],\n",
       "        [60, 60, 60],\n",
       "        [65, 65, 65]])"
      ]
     },
     "execution_count": 945,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_stacked1 = torch.stack([btens, btens, btens], dim=1) # Column Stacking\n",
    "b_stacked1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "5378cec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original ctens: tensor([[[[0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.]]]])\n",
      "Original ctens shape: torch.Size([1, 2, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "# Squeezing and Unsqueezing\n",
    "ctens = torch.zeros(1,2,1,4)\n",
    "print(f'Original ctens: {ctens}')\n",
    "print(f\"Original ctens shape: {ctens.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "id": "59656446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Squeezed ctens: tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Shape of squeezed ctens: torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Squeezed ctens: {torch.squeeze(ctens)}\") # Less square brackets\n",
    "print(f\"Shape of squeezed ctens: {torch.squeeze(ctens).shape}\") # Removes all 1 dims / extra dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 948,
   "id": "9d22b753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dtens: tensor([[[0.4855, 0.6646, 0.1143, 0.8907],\n",
      "         [0.3764, 0.6323, 0.3431, 0.0253],\n",
      "         [0.4094, 0.5202, 0.1545, 0.5854]],\n",
      "\n",
      "        [[0.0350, 0.1388, 0.6834, 0.7266],\n",
      "         [0.3758, 0.8598, 0.1552, 0.1022],\n",
      "         [0.1558, 0.7550, 0.6614, 0.5982]]])\n",
      "Shape of original dtens: torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "dtens = torch.rand(2,3,4)\n",
    "print(f'Original dtens: {dtens}')\n",
    "print(f'Shape of original dtens: {dtens.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 949,
   "id": "1b6f157a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsqueezed dtens when `dim` = 0: tensor([[[[0.4855, 0.6646, 0.1143, 0.8907],\n",
      "          [0.3764, 0.6323, 0.3431, 0.0253],\n",
      "          [0.4094, 0.5202, 0.1545, 0.5854]],\n",
      "\n",
      "         [[0.0350, 0.1388, 0.6834, 0.7266],\n",
      "          [0.3758, 0.8598, 0.1552, 0.1022],\n",
      "          [0.1558, 0.7550, 0.6614, 0.5982]]]])\n",
      "Shape of unsqueezed dtens when `dim` = 0: torch.Size([1, 2, 3, 4])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# torch.unsqueeze() - Adds single dimension to target tensor at a specific dimension\n",
    "rng = 1\n",
    "for i in range(0,rng):\n",
    "    dtens_unsqueezed = dtens.unsqueeze(dim=i) \n",
    "    # `dim=0` Existing dimension where single dimension is added\n",
    "    print(f'Unsqueezed dtens when `dim` = {i}: {dtens_unsqueezed}')\n",
    "    print(f'Shape of unsqueezed dtens when `dim` = {i}: {dtens_unsqueezed.shape}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 950,
   "id": "15eb48d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Original etens: torch.Size([222, 224, 3])\n",
      "Shape of Permuted etens: torch.Size([224, 3, 222])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6728, 0.0603, 0.6815],\n",
       "         [0.2306, 0.2800, 0.7685],\n",
       "         [0.1743, 0.6163, 0.1643],\n",
       "         ...,\n",
       "         [0.7810, 0.3440, 0.2457],\n",
       "         [0.9067, 0.6191, 0.1211],\n",
       "         [0.6532, 0.5918, 0.8413]],\n",
       "\n",
       "        [[0.9169, 0.3164, 0.3975],\n",
       "         [0.6474, 0.5463, 0.5337],\n",
       "         [0.6289, 0.8412, 0.8646],\n",
       "         ...,\n",
       "         [0.3038, 0.0922, 0.9058],\n",
       "         [0.1338, 0.7756, 0.2752],\n",
       "         [0.6557, 0.8337, 0.4600]],\n",
       "\n",
       "        [[0.1691, 0.5389, 0.6808],\n",
       "         [0.8711, 0.1514, 0.0334],\n",
       "         [0.6186, 0.5743, 0.8249],\n",
       "         ...,\n",
       "         [0.3504, 0.1944, 0.3149],\n",
       "         [0.2861, 0.8190, 0.0076],\n",
       "         [0.0194, 0.1645, 0.2291]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.1991, 0.4650, 0.6778],\n",
       "         [0.9613, 0.0918, 0.5338],\n",
       "         [0.4334, 0.1183, 0.6962],\n",
       "         ...,\n",
       "         [0.2737, 0.5545, 0.2927],\n",
       "         [0.1775, 0.9241, 0.8708],\n",
       "         [0.4036, 0.7623, 0.9566]],\n",
       "\n",
       "        [[0.4805, 0.5964, 0.5469],\n",
       "         [0.0637, 0.3955, 0.2255],\n",
       "         [0.4427, 0.0419, 0.7327],\n",
       "         ...,\n",
       "         [0.7297, 0.5497, 0.3485],\n",
       "         [0.0018, 0.5728, 0.1792],\n",
       "         [0.4346, 0.9458, 0.8052]],\n",
       "\n",
       "        [[0.3672, 0.1921, 0.0598],\n",
       "         [0.3727, 0.7029, 0.2528],\n",
       "         [0.9597, 0.6893, 0.6340],\n",
       "         ...,\n",
       "         [0.0967, 0.0222, 0.7016],\n",
       "         [0.1229, 0.3530, 0.6305],\n",
       "         [0.3564, 0.6790, 0.9486]]])"
      ]
     },
     "execution_count": 950,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Permutation - Swap dimension position, it's a view - shares same memory as original input tensor\n",
    "etens = torch.rand(222,224,3) # Image Tensor\n",
    "print(f'Shape of Original etens: {etens.shape}')\n",
    "\n",
    "etens_permute = etens.permute(1, 2, 0) \n",
    "# Shifts axis 0->2, 1->0, 2->1\n",
    "print(f'Shape of Permuted etens: {etens_permute.shape}')\n",
    "\n",
    "etens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 951,
   "id": "a01534ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.6728), tensor(0.6728))"
      ]
     },
     "execution_count": 951,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(etens[0, 0, 0] == etens[0][0][0])\n",
    "etens[0, 0, 0], etens[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "id": "d85d56af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etens[0, 0, 0] == etens_permute[0, 0, 0] # View so shares same memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "id": "2c8b9cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etens value at loc: 0.6728498935699463\n",
      "etens_permute at loc: 0.6728498935699463\n"
     ]
    }
   ],
   "source": [
    "print(f'etens value at loc: {etens[0, 0, 0]}')\n",
    "print(f'etens_permute at loc: {etens_permute[0, 0, 0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "id": "4a63bb65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etens value at loc: 0.9778876900672913\n",
      "etens_permute at loc: 0.9778876900672913\n"
     ]
    }
   ],
   "source": [
    "etens[1, 1, 1] = 0.9778877 # Changing value at specific location\n",
    "\n",
    "print(f'etens value at loc: {etens[1, 1, 1]}')\n",
    "print(f'etens_permute at loc: {etens_permute[1, 1, 1]}')\n",
    "\n",
    "# Since, the tensors are permuted only elements at [i, i, i] index are same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f992a6",
   "metadata": {},
   "source": [
    "### Indexing - Selecting data from tensors\n",
    "\n",
    "Indexing with PyTorch is similar to indexing with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "9974ed45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 955,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "new_tens, new_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 956,
   "id": "9dd0de4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 956,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing\n",
    "new_tens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 957,
   "id": "0af18e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True])"
      ]
     },
     "execution_count": 957,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens[0][1] == new_tens[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 958,
   "id": "3ec56c31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(4))"
      ]
     },
     "execution_count": 958,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens[0][0][0], new_tens[0, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 959,
   "id": "19c7fa39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 959,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens[0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "id": "9bced920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 960,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of a target dimension\n",
    "new_tens[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "id": "e1c90d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 961,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0th and 1st dimension but only index 1 of 2nd dimension\n",
    "new_tens[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "id": "d45b4199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 962,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all values of 0 dimension and index 1 of 1st and 2nd dimension\n",
    "new_tens[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 963,
   "id": "cd24f673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 963,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 964,
   "id": "728e8a39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 964,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 965,
   "id": "7dcc31de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 5, 8]])"
      ]
     },
     "execution_count": 965,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "id": "9ac34961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 966,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens[:] # 3 Layers of Square Brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "id": "71a2d498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 967,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens[0] # Only 2 Layers of Square Brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "id": "fd00a607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 6, 9]]), tensor([[7, 8, 9]]), tensor([9]))"
      ]
     },
     "execution_count": 968,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tens[:, :, 2], new_tens[:, 2], new_tens[:, 2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d37f9f",
   "metadata": {},
   "source": [
    "### PyTorch Tensors and NumPy\n",
    "\n",
    "NumPy is a popular scientific python numerical computing library.\n",
    "\n",
    "And because of this, PyTorch has functionality to interact with it. \n",
    "\n",
    "- Data in NumPy into PyTorch Tensor -> `torch.from_numpy(ndarray)`\n",
    "- PyTorch Tensor into NumPy -> `torch.Tensor.numpy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6768c50",
   "metadata": {},
   "source": [
    "**NumPy Array to PyTorch Tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "id": "bbf2050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy Array: [1. 2. 3. 4. 5. 6. 7.]\n",
      "PyTorch Tensor: tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "\n",
    "print(f'Numpy Array: {array}')\n",
    "print(f'PyTorch Tensor: {tensor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "7d98a981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' When converting from Tensor to Array, dtype changes to float64 '"
      ]
     },
     "execution_count": 970,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datatype of NumPy Array and PyTorch Tensor\n",
    "arrayx = np.arange(1.0, 8.0)\n",
    "tensx = torch.arange(1.0, 8.0)\n",
    "\n",
    "arrayx.dtype, tensx.dtype # Default dtypes\n",
    "\n",
    "''' When converting from Tensor to Array, dtype changes to float64 '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "id": "9bd37ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.float32)"
      ]
     },
     "execution_count": 971,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing dtypes while changing from Array to Tensor\n",
    "array2tens = torch.from_numpy(arrayx).type(torch.float32)\n",
    "array2tens, array2tens.dtype # Keeps dtype as float32 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5181c4e6",
   "metadata": {},
   "source": [
    "**PyTorch Tensor to NumPy Array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "id": "2240ce61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Tensor: tensor([1., 2., 3., 4., 5., 6., 7., 8.]) and Dtype is torch.float32\n",
      "Numpy Array: [1. 2. 3. 4. 5. 6. 7. 8.] and Dtype is float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' NumPy array produced by converting PyTorch Tensor will have float32 as dtype '"
      ]
     },
     "execution_count": 972,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensx = torch.arange(1.0, 9.0) # Default dtype of tensor is float32\n",
    "ndarray = tensx.numpy() # Default dtype numpy is float64\n",
    "\n",
    "print(f'PyTorch Tensor: {tensx} and Dtype is {tensx.dtype}') \n",
    "print(f'Numpy Array: {ndarray} and Dtype is {ndarray.dtype}')\n",
    "\n",
    "''' NumPy array produced by converting PyTorch Tensor will have float32 as dtype '''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c8391b",
   "metadata": {},
   "source": [
    "### PyTorch Reproducibility - Taking away Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "id": "786f2749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0901, 0.3984, 0.9304],\n",
       "        [0.5401, 0.6983, 0.7667],\n",
       "        [0.0403, 0.1155, 0.0231]])"
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3, 3) # Different values for each execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "id": "476528b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False],\n",
       "        [False, False, False],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 974,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3,3) == torch.rand(3,3) # Nearly always False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "id": "f586a20a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ptens: tensor([[0.7196, 0.7307, 0.8278],\n",
      "        [0.1343, 0.6280, 0.7297],\n",
      "        [0.2882, 0.2112, 0.9836]])\n",
      "qtens: tensor([[0.7196, 0.7307, 0.8278],\n",
      "        [0.1343, 0.6280, 0.7297],\n",
      "        [0.2882, 0.2112, 0.9836]])\n",
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed\n",
    "\n",
    "RANDOM_SEED = 44\n",
    "torch.manual_seed(RANDOM_SEED) \n",
    "# Seeds need to set before creation of every new random tensor\n",
    "ptens = torch.rand(3, 3)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "qtens = torch.rand(3, 3)\n",
    "\n",
    "print(f\"ptens: {ptens}\")\n",
    "print(f\"qtens: {qtens}\")\n",
    "\n",
    "print(ptens == qtens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598c4164",
   "metadata": {},
   "source": [
    "### Running Tensors and PyTorch objects on the GPUs\n",
    "\n",
    "- Faster computations, due to CUDA + NVIDIA Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "e6f250da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  4 15:41:49 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 572.83                 Driver Version: 572.83         CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4060 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   44C    P8              1W /   88W |    1916MiB /   8188MiB |      4%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1892    C+G   ...4__cv1g1gvanyjgm\\WhatsApp.exe      N/A      |\n",
      "|    0   N/A  N/A            3492    C+G   ...x64__dt26b99r8h8gj\\RtkUWP.exe      N/A      |\n",
      "|    0   N/A  N/A            9964    C+G   ...5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A           12672    C+G   ...efSharp.BrowserSubprocess.exe      N/A      |\n",
      "|    0   N/A  N/A           12696    C+G   ...xyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           12740    C+G   ...dgb7efx6bt\\app\\QuickPanel.exe      N/A      |\n",
      "|    0   N/A  N/A           13812    C+G   C:\\Windows\\explorer.exe               N/A      |\n",
      "|    0   N/A  N/A           15024    C+G   ..._cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15048    C+G   ...y\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           15916    C+G   ...App_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A           16292    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           16356    C+G   ...em32\\ApplicationFrameHost.exe      N/A      |\n",
      "|    0   N/A  N/A           16396    C+G   ...ef.win7x64\\steamwebhelper.exe      N/A      |\n",
      "|    0   N/A  N/A           16544    C+G   ...ms\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A           16596    C+G   ...s\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A           17844    C+G   ...8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A           18032    C+G   ...IA app\\CEF\\NVIDIA Overlay.exe      N/A      |\n",
      "|    0   N/A  N/A           21020    C+G   ...indows\\System32\\ShellHost.exe      N/A      |\n",
      "|    0   N/A  N/A           22424    C+G   ...s\\Mozilla Firefox\\firefox.exe      N/A      |\n",
      "|    0   N/A  N/A           22800    C+G   ...7efx6bt\\app\\PredatorSense.exe      N/A      |\n",
      "|    0   N/A  N/A           27804      C   ...envs\\gpt2_finetune\\python.exe      N/A      |\n",
      "|    0   N/A  N/A           36984    C+G   ...t\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A           38304    C+G   ...ntrolPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A           38516    C+G   ...8aw4\\AcerPurifiedVoiceApp.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6818c1c",
   "metadata": {},
   "source": [
    "### Setup Device Agnostic Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "2a55f9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup Devices\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "id": "c11ce156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the numbers\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4b3b5",
   "metadata": {},
   "source": [
    "### Putting Tensors and Models on the GPU for faster computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "id": "ca1abfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3]), device(type='cpu'))"
      ]
     },
     "execution_count": 979,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_tens = torch.tensor([1,2,3])\n",
    "cp_tens, cp_tens.device # On CPU by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "id": "0cd02d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 2, 3], device='cuda:0'), device(type='cuda', index=0))"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU if available\n",
    "gp_tens = cp_tens.to(device)\n",
    "gp_tens, gp_tens.device # Index 0 - GPU Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "id": "78ec5ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' gp_tens.numpy() -> Error '"
      ]
     },
     "execution_count": 981,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If tensor is on GPU, can't convert to NumPy since it only works on CPU\n",
    "''' gp_tens.numpy() -> Error '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "id": "53a44cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp_tens_2 = gp_tens.cpu() # Move back to CPU for NumPy Conversion\n",
    "cp_tens_2.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27390ae5",
   "metadata": {},
   "source": [
    "`pytorch.io` for Exercises and Extra Curriculum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt2_finetune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
